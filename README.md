# SLM
基于n-gram的中文拼写检错

**不提供数据。备份使用，不做正式分享。**

该方案的初步结果可以参考[我的博客](https://zhpmatrix.github.io/2018/12/17/chinese-spell-checker/)，博客中同时回顾了一些其他方案的结果。

**基本思路**

检错逻辑（已实现）：

+ 训练一个统计语言模型（KenLM）
+ 用上述模型计算包含错字的句子的n-gram得分
+ 设定n-gram得分的阈值作为筛选错字的依据

纠错逻辑（未实现）：

+ 基于检错时定位的错误词，用百度API，以错误词的拼音作为输入，返回候选正确词列表（因为这是拼写纠错）
+ 用候选词替换错误词，计算整句的ppl得分
+ 设定ppl的阈值作为纠错依据

备注：实际上纠错逻辑是可以用一个标准的召回-排序框架来做。

**如何构建候选正确词表？（混淆集）**

+ Github上已经整理的常见的错误集合（也可以从许多中文网上收集）
+ 百度输入法
+ 挖掘一些常见的n-gram搭配

**如何精准定位错误词的位置？**

n-gram的得分是一个重要feature，单独使用是不够的，可以结合多种策略共同确定。（实际上，在用该方法检错的时候，尝试了很多策略组合，效果差强人意。如果你有更好的策略，请告诉我吧。）

**如何更加高效地纠错？**

把召回-排序的思路玩儿溜。（实际上，这也是在做中文纠错的时候，看到业界用的最多的方案。）
